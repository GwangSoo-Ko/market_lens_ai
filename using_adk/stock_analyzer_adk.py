import os
import sys
import glob
import pandas as pd
import asyncio
import time
from typing import Dict, List, Optional, Tuple
from uuid import uuid4

# ADK ë° GenAI ê´€ë ¨
try:
    from google.adk.agents import Agent  # type: ignore[import-not-found]
    from google.adk.tools import google_search  # type: ignore[import-not-found]
except ImportError:
    print("âŒ google-adk íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install google-adk")
    sys.exit(1)

from adk_utils import AdkAgentRunner, print_runtime_llm_config, _ensure_google_api_key

try:
    # ê¸°ì¡´ ê·¼ê±° ë°ì´í„° ìƒì„± ë¡œì§(ë™ì¼ ë™ì‘ ìœ ì§€)
    # NOTE: stock_analyzer.pyëŠ” google-genai/yfinance/ta-lib ì˜ì¡´ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì„¤ì¹˜ í•„ìš”
    from google import genai
    from google.genai import types
    
    from stock_analyzer import (
        API_DELAY,
        DEFAULT_MODEL,
        MARKET_DATA_OUTPUT_DIR,
        MARKET_INFO,
        STRATEGY_INFO,
        create_analyzer_output_dir,
        fetch_and_save_market_data_for_stock,
        get_latest_screener_dir,
    )
except Exception as e:
    print("âŒ ê¸°ì¡´ stock_analyzer ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨:", str(e))
    print("   requirements.txtì˜ ì˜ì¡´ì„±(google-genai, yfinance, ta-lib ë“±)ì„ ì„¤ì¹˜í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)


# ì‚¬ìš©ìê°€ gemini-2.5-flashë¡œ ì„¤ì •í–ˆìœ¼ë‚˜, ë°˜ë³µ ìƒì„± ë¬¸ì œê°€ ìˆë‹¤ë©´ 1.5ë¡œ ë¡¤ë°± ê¶Œì¥
ADK_DEFAULT_MODEL = os.environ.get("MARKET_LENS_ADK_MODEL", "gemini-2.5-flash")


class StockAnalyzerADK:
    def __init__(self, model: str = ADK_DEFAULT_MODEL, use_tools: bool = False):
        # ADKëŠ” toolsë¥¼ function callingìœ¼ë¡œ ì‹¤í–‰í•˜ë¯€ë¡œ, tool ì§€ì› ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥
        self.model = model or ADK_DEFAULT_MODEL
        self.use_tools = bool(use_tools)
        self.market_data_dir: Optional[str] = None
        
        # íŒŒì¼ ì—…ë¡œë“œë¥¼ ìœ„í•œ GenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        _ensure_google_api_key()
        api_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")
        self.client = genai.Client(api_key=api_key)

        if self.use_tools:
            instruction = (
                "ë„ˆëŠ” ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì—ì„œ ì¼í•˜ëŠ” ì‹œë‹ˆì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ë‹¤. "
                "ì‚¬ìš©ìê°€ ì œê³µí•œ ì¢…ëª©ì„ 10ë‹¨ê³„ ëª©ì°¨ì— ë”°ë¼ ë¶„ì„ ë³´ê³ ì„œ í˜•íƒœë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
                "í•„ìš”í•˜ë©´ google_search ë„êµ¬ë¡œ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ê³ , ì²¨ë¶€ëœ CSV íŒŒì¼(ê°€ê²©/ì§€í‘œ, ì¬ë¬´)ì„ ìš°ì„  ê·¼ê±°ë¡œ ì‚¬ìš©í•œë‹¤."
            )
            tools = [google_search]
        else:
            # Tool-less ëª¨ë“œ (ì‚¬ìš© ì•ˆí•¨)
            instruction = (
                "ë„ˆëŠ” ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì—ì„œ ì¼í•˜ëŠ” ì‹œë‹ˆì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ë‹¤. "
                "ì‚¬ìš©ìê°€ ì œê³µí•œ ì¢…ëª©ì„ 10ë‹¨ê³„ ëª©ì°¨ì— ë”°ë¼ ë¶„ì„ ë³´ê³ ì„œ í˜•íƒœë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
                "í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ í…ìŠ¤íŠ¸ ê·¼ê±° ë°ì´í„°ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë¶„ì„í•˜ë¼."
            )
            tools = []

        self._agent = Agent(
            name="market_lens_stock_analyst",
            model=self.model,
            instruction=instruction,
            description="Market Lens AI - Stock Analysis Agent (ADK)",
            tools=tools,
        )
        self._runner = AdkAgentRunner(self._agent)

    def prepare_evidence_for_row(self, row: pd.Series, market: str = "us") -> tuple[str, str]:
        """
        í•œ ì¢…ëª©ì— ëŒ€í•´ yfinance/ta-libë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ CSVë¡œ ì €ì¥í•˜ê³  ê²½ë¡œ ë°˜í™˜.
        ìˆœì°¨ ì‹¤í–‰ í™˜ê²½ì—ì„œ í˜¸ì¶œë¨.
        """
        ticker = row.get("ticker")
        if not ticker:
            return "", ""

        # ì‹œì¥ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
        output_date = pd.Timestamp.now().strftime("%Y%m%d")
        self.market_data_dir = os.path.join(MARKET_DATA_OUTPUT_DIR, output_date)
        os.makedirs(self.market_data_dir, exist_ok=True)

        _, price_csv, fin_csv = fetch_and_save_market_data_for_stock(
            ticker, market, self.market_data_dir
        )
        return price_csv or "", fin_csv or ""

    def build_evidence_text(self, price_csv: str, fin_csv: str, max_chars: int = 15000) -> str:
        """
        ë¡œì»¬ CSV íŒŒì¼ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì½ì–´ ìš”ì•½/í—¤ë“œë§Œ ë°˜í™˜.
        ADK Function Callingì´ ì•ˆ ë  ë•Œ í”„ë¡¬í”„íŠ¸ì— í…ìŠ¤íŠ¸ë¡œ ì£¼ì…í•˜ê¸° ìœ„í•¨.
        (í˜„ì¬ íŒŒì¼ ì²¨ë¶€ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ë˜ì–´ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
        """
        parts = []
        if price_csv and os.path.exists(price_csv):
            try:
                dfp = pd.read_csv(price_csv)
                if not dfp.empty:
                    parts.append("[PRICE_INDICATOR_HEAD_30]")
                    parts.append(dfp.tail(30).to_csv(index=False))  # ìµœê·¼ 30ì¼
                    parts.append("\n[PRICE_SUMMARY]")
                    parts.append(dfp.describe().to_string())
            except Exception as e:
                parts.append(f"[PRICE_CSV_ERROR] {e}")

        if fin_csv and os.path.exists(fin_csv):
            try:
                dff = pd.read_csv(fin_csv)
                if not dff.empty:
                    parts.append("[FIN_HEAD_30]")
                    parts.append(dff.head(30).to_csv(index=False))
            except Exception as e:
                parts.append(f"[FIN_CSV_ERROR] {e}")

        text = "\n".join([p for p in parts if p])
        if len(text) > max_chars:
            return text[: max_chars - 200] + "\n...[TRUNCATED]..."
        return text

    def analyze_strategy(
        self,
        df: pd.DataFrame,
        strategy: str,
        max_stocks: int = 10,
        market: Optional[str] = None,
        concurrency: int = 1,
    ) -> List[Dict]:
        results: List[Dict] = []
        strategy_info = STRATEGY_INFO.get(strategy, {})

        print(f"\nğŸ“Š {strategy_info.get('name', strategy)} ì „ëµ ë¶„ì„ ì‹œì‘...")
        print(f"   ì´ {len(df)}ê°œ ì¢…ëª© ì¤‘ ìƒìœ„ {min(len(df), max_stocks)}ê°œ ë¶„ì„")

        # ë³‘ë ¬ ì‹¤í–‰ (asyncio.gather + ê°œë³„ Runner)
        # - ParallelAgentëŠ” ê°œë³„ íŒŒì¼ ì²¨ë¶€ê°€ ì–´ë ¤ì›Œ, ë…ë¦½ ì„¸ì…˜ ë³‘ë ¬ ì‹¤í–‰ ë°©ì‹ìœ¼ë¡œ ì „í™˜í•¨.
        # - yfinance ë°ì´í„° ì¤€ë¹„ëŠ” ìˆœì°¨ ì²˜ë¦¬ (Rate Limit)
        if int(concurrency) > 1:
            head_df = df.head(max_stocks).reset_index(drop=True)
            batch_size = int(concurrency)

            final_results: List[Dict] = []

            # 1) ìˆœì°¨ì ìœ¼ë¡œ Evidence(CSV) ì¤€ë¹„
            prepared_data: List[Dict] = []
            for i in range(len(head_df)):
                row = head_df.iloc[i]
                ticker = row.get("ticker", "Unknown")
                name = row.get("name", "Unknown")
                print(f"   [{i+1}/{len(head_df)}] {ticker} ({name}) ê·¼ê±° ë°ì´í„° ìƒì„± ì¤‘...(ìˆœì°¨)")

                price_csv, fin_csv = self.prepare_evidence_for_row(row, market=market)

                prompt = self._create_analysis_prompt(
                    row=row,
                    strategy=strategy,
                    market=market,
                    evidence_price_csv=price_csv,
                    evidence_fin_csv=fin_csv,
                )

                prepared_data.append({
                    "idx": i,
                    "ticker": ticker,
                    "name": name,
                    "row": row,
                    "prompt": prompt,
                    "price_csv": price_csv,
                    "fin_csv": fin_csv,
                })

                if i < len(head_df) - 1:
                    time.sleep(API_DELAY)

            # 2) ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì‹¤í–‰ (asyncio.gather)
            for i in range(0, len(prepared_data), batch_size):
                batch = prepared_data[i : i + batch_size]
                print(f"\n   ğŸš€ Batch [{i+1}~{min(i+batch_size, len(prepared_data))}/{len(prepared_data)}] ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰ ì¤‘...")

                # ë‚´ë¶€ async í•¨ìˆ˜ ì •ì˜ (ë™ê¸° ë©”ì„œë“œ ë‚´ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•¨)
                async def _run_batch_async(batch_items):
                    async def _analyze_one(item):
                        # íŒŒì¼ ì—…ë¡œë“œ -> Content ìƒì„± -> Runner ì‹¤í–‰ -> íŒŒì¼ ì‚­ì œ
                        ticker = item["ticker"]
                        uploaded_files = []
                        try:
                            # íŒŒì¼ ì—…ë¡œë“œ (ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ë¸”ë¡œí‚¹ ë°©ì§€)
                            if item["price_csv"]:
                                f1 = await asyncio.to_thread(
                                    self.client.files.upload,
                                    file=item["price_csv"],
                                    config=types.UploadFileConfig(mime_type='text/csv')
                                )
                                uploaded_files.append(f1)
                            if item["fin_csv"]:
                                f2 = await asyncio.to_thread(
                                    self.client.files.upload,
                                    file=item["fin_csv"],
                                    config=types.UploadFileConfig(mime_type='text/csv')
                                )
                                uploaded_files.append(f2)
                            
                            # Content êµ¬ì„± (í”„ë¡¬í”„íŠ¸ + íŒŒì¼)
                            # types.Content ìƒì„± ì‹œ strì´ë‚˜ File ê°ì²´ë¥¼ ì§ì ‘ ë„£ìœ¼ë©´ Pydantic ê²€ì¦ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥
                            # ëª…ì‹œì ìœ¼ë¡œ types.Part ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ êµ¬ì„±í•¨
                            parts = [types.Part(text=item["prompt"])]
                            for f in uploaded_files:
                                # File ê°ì²´ -> Part(file_data=...) ë³€í™˜
                                parts.append(types.Part(
                                    file_data=types.FileData(
                                        mime_type=f.mime_type, 
                                        file_uri=f.uri
                                    )
                                ))
                            
                            new_message = types.Content(role="user", parts=parts)
                            
                            # Runner ì‹¤í–‰ (ë…ë¦½ ì„¸ì…˜)
                            result_text = await self._runner.run_text_async(
                                prompt="", # new_messageë¡œ ì „ë‹¬í•˜ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´
                                new_message=new_message,
                                session_id=str(uuid4()) # ë…ë¦½ ì„¸ì…˜
                            )
                            
                            # íŒŒì¼ ì •ë¦¬
                            for f in uploaded_files:
                                try:
                                    await asyncio.to_thread(self.client.files.delete, name=f.name)
                                except: pass
                                
                            return {
                                "ticker": item["ticker"],
                                "name": item["name"],
                                "strategy": strategy,
                                "analysis": result_text,
                                "data": item["row"].to_dict(),
                            }
                        except Exception as e:
                            print(f"       âŒ {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
                            # íŒŒì¼ ì •ë¦¬ (ì—ëŸ¬ ì‹œì—ë„)
                            for f in uploaded_files:
                                try:
                                    await asyncio.to_thread(self.client.files.delete, name=f.name)
                                except: pass
                            return None

                    tasks = [_analyze_one(item) for item in batch_items]
                    return await asyncio.gather(*tasks)

                # asyncio.runìœ¼ë¡œ ë¹„ë™ê¸° ë°°ì¹˜ ì‹¤í–‰
                batch_results = asyncio.run(_run_batch_async(batch))
                
                for res in batch_results:
                    if res:
                        print(f"       âœ… ì™„ë£Œ: {res['ticker']}")
                        final_results.append(res)
            
            return final_results

        # ìˆœì°¨ ì‹¤í–‰ (Concurrency=1)
        for idx, (_, row) in enumerate(df.head(max_stocks).iterrows()):
            ticker = row.get("ticker", "Unknown")
            name = row.get("name", "Unknown")
            print(f"   [{idx+1}/{min(len(df), max_stocks)}] {ticker} ({name}) ë¶„ì„ ì¤‘...")

            try:
                # 1. ê·¼ê±° ë°ì´í„° ìƒì„± (yfinance)
                price_csv, fin_csv = self.prepare_evidence_for_row(row, market=market)

                # 2. ë¶„ì„ ìˆ˜í–‰ (ADK í˜¸ì¶œ - íŒŒì¼ ì²¨ë¶€ ë°©ì‹)
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self._create_analysis_prompt(
                    row=row,
                    strategy=strategy,
                    market=market,
                    evidence_price_csv=price_csv,
                    evidence_fin_csv=fin_csv,
                )

                # íŒŒì¼ ì—…ë¡œë“œ
                uploaded_files = []
                if price_csv:
                    f1 = self.client.files.upload(file=price_csv, config=types.UploadFileConfig(mime_type='text/csv'))
                    uploaded_files.append(f1)
                if fin_csv:
                    f2 = self.client.files.upload(file=fin_csv, config=types.UploadFileConfig(mime_type='text/csv'))
                    uploaded_files.append(f2)

                # Content ìƒì„±
                parts = [prompt]
                for f in uploaded_files:
                    parts.append(f)
                
                new_message = types.Content(role="user", parts=parts)
                
                # ì‹¤í–‰ (ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì´ë¯€ë¡œ asyncio.run ì‚¬ìš©)
                analysis_text = asyncio.run(self._runner.run_text_async(prompt="", new_message=new_message, session_id=str(uuid4())))
                
                # íŒŒì¼ ì‚­ì œ
                for f in uploaded_files:
                    try:
                        self.client.files.delete(name=f.name)
                    except: pass

                if analysis_text:
                    results.append({
                        "ticker": ticker,
                        "name": name,
                        "strategy": strategy,
                        "analysis": analysis_text,
                        "data": row.to_dict(),
                    })
                
                time.sleep(API_DELAY)

            except Exception as e:
                print(f"       âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                # import traceback
                # traceback.print_exc()

        return results

    def _create_analysis_prompt(
        self,
        row: pd.Series,
        strategy: str,
        market: Optional[str],
        evidence_price_csv: str = "",
        evidence_fin_csv: str = "",
        evidence_text: str = "",
    ) -> str:
        ticker = row.get("ticker", "Unknown")
        name = row.get("name", "Unknown")
        market_name = MARKET_INFO.get(market, {}).get("name", market) if market else "Global"
        
        # ê¸°ë³¸ ì •ë³´ êµ¬ì„±
        ticker_value = f"{ticker} ({name})" if name != "Unknown" else ticker
        
        # ì „ëµ ë©”íƒ€ë°ì´í„°
        strategy_info = STRATEGY_INFO.get(strategy, {})
        
        # ì¢…ëª© ê¸°ë³¸ ì •ë³´ ë¸”ë¡
        stock_info_lines = [f"### ë¶„ì„ ëŒ€ìƒ: {ticker_value} ({market_name})"]
        for k, v in row.to_dict().items():
            if k not in ["ticker", "name"]:
                stock_info_lines.append(f"- {k}: {v}")
        stock_info = "\n".join(stock_info_lines)

        evidence_block = ""
        # íŒŒì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš° (ì²¨ë¶€ íŒŒì¼ ì•ˆë‚´)
        if evidence_price_csv or evidence_fin_csv:
             evidence_block = "\n".join(
                [
                    "## ê·¼ê±° ë°ì´í„° (ì²¨ë¶€ íŒŒì¼)",
                    "ë¶„ì„ ìš”ì²­ ë©”ì‹œì§€ì— CSV íŒŒì¼(ê°€ê²©/ì§€í‘œ, ì¬ë¬´)ì´ ì²¨ë¶€ë˜ì–´ ìˆë‹¤.",
                    "ì´ íŒŒì¼ë“¤ì˜ ë°ì´í„°ë¥¼ **ìµœìš°ì„  ê·¼ê±°**ë¡œ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•˜ë¼.",
                ]
            )

        return f"""
ë„ˆëŠ” ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì—ì„œ ì¼í•˜ê³  ìˆëŠ” ê¸°ì—… ë¶„ì„ ë° ì£¼ì‹ ì‹œì¥ ë¶„ì„ì˜ ì „ë¬¸ê°€ì•¼. ë„ˆì˜ ì´ë¦„ì€ 'Gemini Stock Analyst'ì•¼. ë„ˆëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì‹ ì¢…ëª©ì—({ticker_value}) ëŒ€í•´ì„œ ê° ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ê³  ìµœì¢… íˆ¬ì ì˜ì‚¬ ê²°ì •ì— ë„ì›€ì„ ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.

ëª©í‘œ ë° ì—­í• :
* ì‚¬ìš©ìê°€ ìš”ì²­í•œ íŠ¹ì • ì£¼ì‹ ì¢…ëª©ì— ëŒ€í•´ ì‹¬ì¸µì ì¸ ê¸°ì—… ë° ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì œê³µí•œë‹¤.
* ë³´ê³ ì„œëŠ” íˆ¬ì ì˜ì‚¬ ê²°ì •ì— ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë„ë¡ ìµœì‹  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„¸í•˜ê³  ê¹Šì´ ìˆê²Œ ì‘ì„±í•œë‹¤.
* ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•˜ë©°, ì „ë¬¸ì ì¸ ë³´ê³ ì„œ ì–‘ì‹ì„ ë”°ë¥¸ë‹¤.
* ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•œë‹¤.

## ìŠ¤í¬ë¦¬ë‹/ì¢…ëª© ë©”íƒ€ ì •ë³´
ì „ëµ: {strategy_info.get('name', strategy)}
ì „ëµ ì„¤ëª…: {strategy_info.get('description', '')}
í•µì‹¬ ì§€í‘œ: {strategy_info.get('focus', '')}

{stock_info}

{evidence_block}

í–‰ë™ ë° ê·œì¹™:
1) ë¶„ì„ ë³´ê³ ì„œ ì‘ì„±:
   a) ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¢…ëª©({ticker_value})ì— ëŒ€í•´, **google_search** ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ì™€ ì´ìŠˆë¥¼ í™•ì¸í•œë‹¤.
   b) ì²¨ë¶€ëœ CSV íŒŒì¼ë“¤ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ëŸ‰ì  ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.
   c) ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ ì œì‹œëœ 10ë‹¨ê³„ ë¶„ì„ ê³¼ì •ì„ ì² ì €íˆ ë”°ë¥¸ë‹¤.
   d) ê° ë‹¨ê³„ë³„ ë¶„ì„ ë‚´ìš©ì€ ê°€ëŠ¥í•œ í•œ ìƒì„¸í•˜ê³  ì‹¬ì¸µì ì´ì–´ì•¼ í•˜ë©°, ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ ëª…í™•í•˜ê²Œ ì œì‹œí•´ì•¼ í•œë‹¤.
   e) íŠ¹íˆ 'ê¸°ìˆ ì  ë¶„ì„' ë‹¨ê³„ì—ì„œëŠ” ìµœê·¼ 1ë…„ê°„ì˜ ì£¼ê°€ íŠ¸ë Œë“œì™€ ì°¨íŠ¸ íŒ¨í„´ ë° ì²¨ë¶€ëœ CSVì˜ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë¶„ì„í•˜ê³ , 'ì¬ë¬´ ìƒíƒœ ë¶„ì„' ë‹¨ê³„ì—ì„œëŠ” ìµœê·¼ 3ê°œë…„ ë° ìµœê·¼ 4ê°œ ë¶„ê¸° ì¬ë¬´ì œí‘œë¥¼ ì¢…í•© ë¶„ì„í•œ ë‚´ìš©ì„ í•„ìˆ˜ë¡œ í¬í•¨í•œë‹¤.
   f) 'ê°€ì¹˜ í‰ê°€' ë‹¨ê³„ì—ì„œëŠ” ì•„ë˜ ì ˆì°¨ì— ëª…ì‹œëœ ê°€ì¹˜í‰ê°€ê¸°ë²•ì„ í•„ìˆ˜ë¡œ í™œìš©í•˜ì—¬ ê¸°ì—…ì˜ ì ì • ê°€ì¹˜ì™€ í˜„ì¬ ì£¼ê°€ë¥¼ ë¹„êµí•˜ì—¬ íˆ¬ì ì˜ê²¬ì„ ì œì‹œí•˜ë„ë¡ í•œë‹¤.
2) 10ë‹¨ê³„ ë¶„ì„ ì ˆì°¨ (ë³´ê³ ì„œ ëª©ì°¨):
   1. íšŒì‚¬ ê°œìš”: ê¸°ì—…ì˜ í•µì‹¬ ì‚¬ì—…, ì—­ì‚¬, í˜„ì¬ ì‹œì¥ ìœ„ì¹˜.
   2. ê¸°ìˆ ì  ë¶„ì„: ìµœì‹  ìë£Œë¥¼ ì°¸ê³ í•œ ê°€ê²© ì›€ì§ì„, ìˆ˜ê¸‰ ìƒí™©, ì¶”ì„¸, ëª¨ë©˜í…€ ë“±ì˜ ê¸°ìˆ ì  ì§€í‘œ ë° ì°¨íŠ¸ ë¶„ì„.
   3. ì¬ë¬´ ìƒíƒœ ë¶„ì„: í˜„ì¬ ì‹œì ìœ¼ë¡œë¶€í„° ìµœê·¼ 3ê°œë…„ íšŒê³„ ì—°ë„ ë° ìµœê·¼ 4ê°œ ë¶„ê¸° ì¬ë¬´ì œí‘œ(ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ, ë¶€ì±„ë¹„ìœ¨ ë“±) ì¢…í•© ë¶„ì„.
   4. ì •ì„±ì  ë¦¬ì„œì¹˜: ì†í•œ ì‚°ì—… ê°œìš”, ê²½ìŸ êµ¬ë„, ê¸°ì—…ì˜ ê²½ìŸ ìš°ìœ„ ë° ì§€ì† ê°€ëŠ¥ì„±, ê±°ë²„ë„ŒìŠ¤ ë“± ì •ì„±ì  ìš”ì†Œ í‰ê°€.
   5. ë§¤í¬ë¡œì  ê³ ë ¤ì‚¬í•­: ê±°ì‹œ ê²½ì œ í™˜ê²½(ê¸ˆë¦¬, ì¸í”Œë ˆì´ì…˜, í™˜ìœ¨ ë“±)ì´ ê¸°ì—… ì‚¬ì—… ë° ì‹¤ì ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„.
   6. ê°€ì¹˜ í‰ê°€: ìƒëŒ€ê°€ì¹˜í‰ê°€(Peer Group Analysis)ì™€ ë‚´ì¬ê°€ì¹˜í‰ê°€ë°©ë²•(DCF, Reverse DCF, DDM, RIM)ì„ í™œìš©í•˜ì—¬ ì ì • ê°€ì¹˜ ë„ì¶œ ë° í˜„ì¬ ì£¼ê°€ ëŒ€ë¹„ íˆ¬ì ì˜ê²¬ ì œì‹œ (ì˜ˆ: 'ë§¤ìˆ˜', 'ë³´ìœ ', 'ë§¤ë„').
   7. ë¦¬ìŠ¤í¬ í‰ê°€: íˆ¬ì ì‹œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸(ê²½ì˜, ì‚°ì—…, ê·œì œ ë“±)ê³¼ ë¦¬ìŠ¤í¬ ì™„í™” ìš”ì†Œ ì œì‹œ.
    8. ì™¸ë¶€ ë¶„ì„ í‰ê°€: ì™¸ë¶€ ë¦¬ì„œì¹˜ ë° ë¶„ì„ ë³´ê³ ì„œì˜ ì£¼ìš” ê°€ì„¤ ë° ë‚´ìš©ì— ëŒ€í•œ ë¹„êµ ë° ì˜ê²¬ ì œì‹œ.
   9. í˜„ì¬ ì‹œì ì˜ íˆ¬ì ë§¤ë ¥ë„ í‰ê°€: ë§¤í¬ë¡œ, ì‹œì¥ ìƒí™©, ì‚°ì—… ì „ë§, ê¸°ì—… ë¹„ì „ ë“±ì„ ì¢…í•©í•œ ìµœì¢… íˆ¬ì ë§¤ë ¥ë„ í‰ê°€.
   10. ìµœì¢… ê²°ë¡  ë° íˆ¬ì ì „ëµ ì œì‹œ: ë¶„ì„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ íˆ¬ì ì˜ì‚¬ ê²°ì •ì— ëŒ€í•œ ìµœì¢… ê²°ë¡  ë° êµ¬ì²´ì ì¸ íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ ì œì‹œ.
3) ì „ë¬¸ì„± ìœ ì§€:
   a) ë‹µë³€ì€ í†µê³„ì  ë°ì´í„°ì™€ ê¸ˆìœµ ì§€í‘œì— ê·¼ê±°í•˜ì—¬ ì‘ì„±í•œë‹¤.
   b) ì£¼ê´€ì ì¸ ê°ì • í‘œí˜„ì´ë‚˜ ë¶ˆí•„ìš”í•œ ì‚¬ì¡±ì€ í”¼í•˜ê³ , ê°ê´€ì ì´ê³  ì‚¬ì‹¤ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë° ì§‘ì¤‘í•œë‹¤.
4) ê·¼ê±° ë°ì´í„° ìš°ì„ :
   a) ì²¨ë¶€ëœ CSV íŒŒì¼ ë°ì´í„°ì™€ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ëŒí•˜ë©´, ì›ì¹™ì ìœ¼ë¡œ ì²¨ë¶€ ë°ì´í„°ë¥¼ ìš°ì„ í•˜ë˜, ì°¨ì´ê°€ ë°œìƒí•œ ì´ìœ (ì‹œì /í†µí™”/ë‹¨ìœ„ ë“±)ë¥¼ ëª…ì‹œí•œë‹¤.
   b) **ì´ì „ì— ìƒì„±í•œ ë‚´ìš©ì„ ë°˜ë³µí•´ì„œ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.**

ì „ë°˜ì ì¸ ì–´ì¡°:
* ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê°ì„ ì£¼ëŠ” ì–´ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤.
* ë³´ê³ ì„œ í˜•ì‹ì— ë§ì¶° ê²©ì‹ ìˆê³  ëª…í™•í•œ ë¬¸ì²´ë¥¼ ìœ ì§€í•œë‹¤.
* ì‚¬ìš©ìì˜ íˆ¬ì ê²°ì •ì„ ì§€ì›í•˜ëŠ” ì¡°ë ¥ìë¡œì„œì˜ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.
"""

    def merge_analysis_reports(self, analyzer_output_dir: str):
        """
        ìƒì„±ëœ analysis_*.md íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ì‹œì¥ë³„ í†µí•© ë³´ê³ ì„œ(investment_report.md)ë¥¼ ìƒì„±í•œë‹¤.
        PortfolioMakerADKê°€ ì˜¬ë°”ë¥¸ ì…ë ¥ íŒŒì¼ì„ ì½ë„ë¡ ë³´ì¥í•˜ê¸° ìœ„í•¨.
        """
        analysis_files = glob.glob(os.path.join(analyzer_output_dir, "analysis_*.md"))
        if not analysis_files:
            return

        print(f"\nğŸ“‘ í†µí•© ë³´ê³ ì„œ ìƒì„± ì¤‘... ({len(analysis_files)}ê°œ íŒŒì¼ ë³‘í•©)")
        
        # ì‹œì¥ë³„ë¡œ ë¶„ë¥˜
        market_files = {}
        for f in analysis_files:
            filename = os.path.basename(f)
            # analysis_us_growth.md -> market=us
            parts = filename.split("_")
            if len(parts) >= 2:
                market = parts[1]
                if market not in market_files:
                    market_files[market] = []
                market_files[market].append(f)

        for market, files in market_files.items():
            combined_report = []
            combined_report.append(f"# {market.upper()} Investment Report (Combined)")
            combined_report.append(f"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n")
            
            for f in files:
                try:
                    with open(f, "r", encoding="utf-8") as rf:
                        content = rf.read()
                        combined_report.append(content)
                        combined_report.append("\n\n---\n\n")
                except Exception as e:
                    print(f"  âš ï¸ ì½ê¸° ì‹¤íŒ¨: {f} / {e}")
            
            output_filename = f"{market}_investment_report.md"
            output_path = os.path.join(analyzer_output_dir, output_filename)
            
            with open(output_path, "w", encoding="utf-8") as wf:
                wf.write("\n".join(combined_report))
            print(f"  âœ… í†µí•© ë³´ê³ ì„œ ì €ì¥: {output_path}")

    def run_analysis(
        self,
        screener_output_dir: str,
        max_stocks_per_strategy: int = 5,
        concurrency: int = 1,
    ) -> Tuple[List[Dict], str]:
        """
        ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ë¡œë“œí•˜ì—¬ ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•œë‹¤.
        (StockAnalyzer.run_analysisì™€ ìœ ì‚¬ ì¸í„°í˜ì´ìŠ¤)
        """
        # 1. ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ë¡œë“œ
        from stock_analyzer import StockAnalyzer
        # ì„ì‹œ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©
        sa_loader = StockAnalyzer(api_key="DUMMY") 
        screening_results = sa_loader.load_screening_results(screener_output_dir)
        
        # 2. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        analyzer_output_dir = create_analyzer_output_dir()
        print(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {analyzer_output_dir}")

        all_results = []

        # 3. ë¶„ì„ ìˆ˜í–‰
        for market, strategies in screening_results.items():
            for strategy, df in strategies.items():
                if df.empty:
                    continue
                
                strategy_results = self.analyze_strategy(
                    df, 
                    strategy, 
                    max_stocks=max_stocks_per_strategy,
                    market=market,
                    concurrency=concurrency
                )
                
                if not strategy_results:
                    continue

                # ë¦¬í¬íŠ¸ ì €ì¥
                filename = f"analysis_{market}_{strategy}.md"
                filepath = os.path.join(analyzer_output_dir, filename)
                
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(f"# {market.upper()} {strategy} Strategy Analysis Report\n\n")
                    f.write(f"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n")
                    f.write(f"Total Stocks: {len(strategy_results)}\n\n")
                    
                    for res in strategy_results:
                        f.write(f"## {res['ticker']} - {res['name']}\n\n")
                        f.write(res['analysis'])
                        f.write("\n\n---\n\n")
                
                print(f"   ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
                all_results.extend(strategy_results)
        
        # 4. í†µí•© ë³´ê³ ì„œ ìƒì„± (PortfolioMakerìš©)
        self.merge_analysis_reports(analyzer_output_dir)
        
        return all_results, analyzer_output_dir


def main():
    import argparse
    parser = argparse.ArgumentParser(description="Market Lens AI - Stock Analyzer (ADK Version)")
    parser.add_argument("--screener-output", type=str, help="Path to screener output directory")
    parser.add_argument("--concurrency", type=int, default=1, help="Number of concurrent LLM calls (default: 1)")
    parser.add_argument("--debug-config", action="store_true", help="Print runtime LLM configuration")
    args = parser.parse_args()

    if args.debug_config:
        print_runtime_llm_config()
    
    analyzer = StockAnalyzerADK(use_tools=True) # ë„êµ¬ ì‚¬ìš© (google_search)

    # 1. ìŠ¤í¬ë¦¬ë„ˆ ê²°ê³¼ ë¡œë“œ
    screener_dir = args.screener_output or get_latest_screener_dir()
    if not screener_dir:
        print("âŒ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # run_analysis ë©”ì„œë“œ ì‚¬ìš©
    all_results, analyzer_dir = analyzer.run_analysis(
        screener_dir,
        max_stocks_per_strategy=999, # CLIì—ì„œ í˜¸ì¶œ ì‹œ ìƒìœ„ ì œí•œì€ analyze_strategy ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ ì²˜ë¦¬
        concurrency=args.concurrency
    )
    
    print("\nâœ¨ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
